---
title: "ETC 5521 Assignment 1 Q2"
author: "Arindom Baruah (32779267)"
format: 
  html:
    number-sections: true
    theme: spacelab
---


![](https://editor.analyticsvidhya.com/uploads/3951420200902_blog_-forecasting-with-time-series-models-using-python_pt2_website.png)


<div class="warning" style='background-color:#8bd69f; color: #000301; border-left: solid #044716 4px; border-radius: 4px; padding:0.7em;'>
<span>
<p style='margin-top:1em; text-align:center'>
<b>What are we trying to study ?</b></p>
<p style='margin-left:1em;'>


<b> A small cafe in the city of Melbourne is interested in determining whether the daily earnings depend on the weather. They compiled data for a period over 2000-2001 to study this question. An initial data analysis for the dataset will be conducted in the following sections to prepare the dataset for further exploratory data 

</p>
<p style='margin-bottom:1em; margin-right:1em; text-align:right; font-family:Georgia'> </b> <i></i>
</p></span>
</div>



```{r library-load}
#| echo: false
#| message: false
#| warning: false
library(kableExtra)
library(tidyverse)
library(here)
library(visdat)
library(lubridate)

```



# Data description

As a part of the initial data analysis, we need to describe the various variables present in the dataset. The variables are described in @tbl-metdata.

```{r}
#| echo: false
#| label: tbl-metdata
#| tbl-cap: "Metadata"

desc <- tibble(var=c("dt", "wday", "revenue", "expend", "precip", "mint", "maxt", "source"),
               description=c("Date", 
              "Day of the week",
              "Daily revenue in hundreds, 11=1100", 
              "Daily expenses in hundreds",
              "Precipitation in mm", 
              "Minimum temperature, Celsius",
              "Maximum temperature, Celsius",
              "Source of the weather data"))
kbl(desc, table.attr = 'data-quarto-disable-processing="true"') |> 
  kable_styling(full_width = FALSE) |>
  column_spec(1, width="2cm", border_right = T) |>
  column_spec(2, width="10cm")
```




```{r load-data}
load("cafe.rda")
```




1. __dt__: Date of observation
2. __wday__: The day of the week corresponding to the observation date.
3. __revenue__: Revenue generated for the observation date.
4. __expend__: Expenditures incurred for the observation date.
5. __precip__: Precipitation value on the observation date.
6. __mint__: Minimum temperature on the observation date.
7. __maxt__: Maximum temperature on the observation date.
8. __source__: Source of the weather data.

Let us get an understanding of how the data looks like by checking @tbl-head.

```{r table}
#| label: tbl-head
#| tbl-cap: "Initial observations of the dataset"

kbl(head(cafe), table.attr = 'data-quarto-disable-processing="true"') |> 
  kable_styling(full_width = FALSE) 

```

# Data screening

The second step in the initial data analysis would be to check for the datatypes associated with each variable. We can identify the datatypes through the glimpse function as shown below.

```{r}
glimpse(cafe)
```


Let us now try to visualise the datatypes using a visdat plot.

```{r}
#| fig-cap: Datatypes for each variable
#| label: fig-datviz

vis_dat(cafe)
```

Based on the glimpsed dataset and @fig-datviz, 

<div class="alert alert-block alert-warning">

⚠️‼️
We are able to observe the following issues with the datatypes of each variables:

1. <b> dt (Date) </b>: The date variable is in the character format and will need to be converted to datetime format.
2. <b> expend (Expenditure) </b>: The expenditure variable is in the character datatype while these are continuous numerical values. Hence, this variable will be converted to a numerical datatype.
3. <b> precip (Precipitation) </b>: The precipitation variable which shows the precipitation value is a character variable while it contains continuous numerical values. Hence, this variable will be converted to a numerical variable. 
</div>


Now that we have identified the variables with the incorrect datatypes, we will transform them into the required datatypes which will allow us to further analyse our dataset.

## Converting date to datetime

In order to convert the dates into suitable format, we will need to conduct a quick __sanity check__. Let us first check the dates in its current form.

```{r}
head(cafe$dt)
```
Based on the above output, we see that the dates are in the format of "MM-DD-YY". Hence, an appropriate treatment to the dates will be done to convert them into the required datetime format as shown through the code chunk below.

```{r}
cafe$dt <- mdy(cafe$dt)
```


## Obtaining day of week from date

While the column "wday" is already in its appropriate format and datatype, however, we will replace this column by obtaining the weekday from the date column. This would serve as an __added validation__ and will prevent any incorrect entries of weekday in the dataset. Furthermore, the column will be converted into an ordered factor datatype which would allow for easier analysis and visualisations in later sections.

```{r}
cafe$wday <- wday(cafe$dt,
                  label = TRUE)
```


## Converting expenditure and precipitation variables

The values of expenditures and precipitations should ideally be numerical in nature as they are continuous values. The following code chunk will convert the datatypes for these variables into a suitable datatype for numerical analysis.

```{r}
#| warning: false
cafe$precip <- as.numeric(cafe$precip)
cafe$expend <- as.numeric(cafe$expend)
```

Let us now visualise the new datatypes using the visdat package once again as illustrated by @fig-newdataviz

```{r}
#| label: fig-newdataviz
#| fig-cap: Datatypes of variables after data screening

vis_dat(cafe)
```

<div class="alert alert-block alert-success">
✅  Upon successful data screening, we now have a dataset with each variable being attributed with an appropriate datatype. ✅
</div>



# Data cleaning

In this section, we will be mainly concerned with the quality of our data. Upon assessing the quality of the data, we will utilise various data cleaning methods to improve the overall usability of the dataset.

## Missing values in the dataset

Let us try to visualise the presence of missing values in the dataset using the vis-miss visualisation.

```{r}
#| label: fig-vismis
#| fig-cap: Missing values in the dataset

vis_miss(cafe)
```


Based on illustration of @fig-vismis,

<div class="alert alert-block alert-warning">

⚠️‼️

While the overall dataset is fairly clean, the missing values constitute about <b> 0.3% </b> of the entire dataset. These missing values are observed in the expenditure,precipitation and the revenue variables. 

⚠️‼️

</div>

